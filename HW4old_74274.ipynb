{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mW2G52XmhNgX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TrtQNnGknoH",
        "outputId": "128faa2f-9786-4488-de08-42fc7c6159ca"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv('/content/gdrive/MyDrive/CS274/CS274H04/hw4_naive.csv')\n",
        "y_val = train_data['Label']\n",
        "train_data.drop(labels = ['Label'], axis=1,inplace=True)\n",
        "X_val = train_data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_val, y_val, test_size=0.2,random_state = 5)"
      ],
      "metadata": {
        "id": "dWD6UwEdx6Nk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def laplace_smoothing(matched_counts, ttl_class, feat_n, cls_n, alpha=1):\n",
        "    #print(matched_counts)\n",
        "#    probs = np.zeros_like(matched_counts)\n",
        "\n",
        "\n",
        "#    for i in range(cls_n):\n",
        "#      probs[i, :] = (matched_counts[i, :] + alpha) / (ttl_class[i] + cls_n )\n",
        "#    return probs\n"
      ],
      "metadata": {
        "id": "ByycpkpsOpFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def fit(xtrain, ytrain, classes, alpha = 1):\n",
        "  #print(xtrain.shape)\n",
        "#  print(ytrain)\n",
        "#  feat_n = xtrain.shape[1] #feature num\n",
        "#  cls_n = len(classes) #number of classes\n",
        "# cls_c = ytrain.value_counts().to_dict() #element num in each class\n",
        "\n",
        "#  mtchd_c = np.zeros((cls_n, feat_n))\n",
        "#  print(mtchd_c.shape)\n",
        "\n",
        "#  for i, cls in enumerate(classes):\n",
        "#    mtchd_d = xtrain[ytrain == cls]\n",
        "#    print(mtchd_d.shape)\n",
        "#    for idx in range(feat_n):\n",
        "#        #print(mtchd_d.iloc[:, idx])\n",
        "#      mtchd_c[i][idx] = mtchd_d.iloc[:, idx].sum()/xtrain.shape[0]\n",
        "#  #print(mtchd_c.shape)\n",
        "\n",
        "#  return laplace_smoothing(mtchd_c, cls_c, feat_n, cls_n, 1)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_A-mwQwPzuco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def prdct(xtest, classes, probs, alpha = 1 ):\n",
        "#  num_features = xtest.shape[1]\n",
        "#  prdcts = np.zeros(xtest.shape[0])\n",
        "#  for idx in range(xtest.shape[0]):\n",
        "#    scores = np.zeros(len(classes))\n",
        "\n",
        "#    for i, label in enumerate(classes):\n",
        "#      label_index = np.where(classes == label)\n",
        "#      score = 0\n",
        "#      for feature_idx in range(num_features):\n",
        "#          feature_value = xtest.iloc[idx,feature_idx]\n",
        "#          if probs[label_index, feature_idx] < 0:\n",
        "#            probs[label_index, feature_idx] = 8 +probs[label_index, feature_idx]\n",
        "#          score += np.log(probs[label_index, feature_idx]) * feature_value\n",
        "#      #print(score)\n",
        "#      scores[i] = score\n",
        "#    #print(scores)\n",
        "#    prdct = classes[np.argmax(scores)]\n",
        "#    prdcts[idx] =  prdct\n",
        "#  return prdcts\n"
      ],
      "metadata": {
        "id": "AqO1FIrXEEAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Mnbfit(xtrain,ytrain):\n",
        "  classes = [0,1]\n",
        "  count_classes = []\n",
        "  ytrain = ytrain.to_numpy()\n",
        "  for i, cls in enumerate(classes):\n",
        "    #print(cls)\n",
        "    count_class = xtrain[ytrain == cls]\n",
        "    count_classes.append(count_class.values)\n",
        "  count_classes = np.array(count_classes)\n",
        "  priors = []\n",
        "  prior0 = np.sum(len(count_classes[0])/len(ytrain))\n",
        "  priors.append(prior0)\n",
        "  prior1 = np.sum(len(count_classes[1])/len(ytrain))\n",
        "  priors.append(prior0)\n",
        "  return (count_classes), priors\n",
        "fitted, priorz = Mnbfit(X_train, y_train)\n",
        "#print(fitted[0])"
      ],
      "metadata": {
        "id": "3nxgLoDqa18d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90a6e2e3-207a-4f10-c31c-724514328774"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-7569c6b46cbf>:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  count_classes = np.array(count_classes)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Mnbprd(xtest, count_class, priors, alpha):\n",
        "  preds = []\n",
        "  for i in range(len(xtest)):\n",
        "    pred0 = np.prod([(np.sum((count_class[0]==xtest.iloc[i].values))+alpha)/(len(count_class[0])+alpha*xtest.shape[1])])\n",
        "    pred1 = np.prod([(np.sum((count_class[1]==xtest.iloc[i].values))+alpha)/(len(count_class[1])+alpha*xtest.shape[1])])\n",
        "    preds.append(0 if (pred0*priors[0]) > (pred1*priors[1])else 1)\n",
        "  return preds\n",
        "\n",
        "y_pred_mnb = Mnbprd(X_test, fitted, priorz,1)"
      ],
      "metadata": {
        "id": "GL_RhRpcXPHf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"accuracy: {accuracy_score(y_test, y_pred_mnb)}\")\n",
        "print(f\"f1Score: {f1_score(y_test, y_pred_mnb, average = 'macro')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nirx4-xICe7L",
        "outputId": "4933500c-e038-47fb-820b-3fe78f9a228a"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.7758928571428572\n",
            "f1Score: 0.7561075063397994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Gnbfit(xtrain, ytrain):\n",
        "  classes = [0,1]\n",
        "  count_classes = []\n",
        "  class_mius = []\n",
        "  class_sigmas = []\n",
        "  class_priors = []\n",
        "  for c in classes:\n",
        "    X_c = xtrain[ytrain == c]\n",
        "    class_mius.append(X_c.mean(axis = 0).values)\n",
        "    class_sigmas.append(X_c.std(axis = 0).values )\n",
        "    class_priors.append(np.sum(((X_c) / len(xtrain)).values))\n",
        "  return class_mius, class_sigmas, class_priors\n",
        "mius, sigmas, priors = Gnbfit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Q3fvcrpFgCtl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Gnbprd(xtest, miu, sigma, prior):\n",
        "  preds = []\n",
        "  classes = [0,1]\n",
        "  #print(miu)\n",
        "  for x in xtest.values:\n",
        "    pred0 = (np.prod((1 / (np.sqrt(2 * np.pi) * sigma[0])) * np.exp(-((x - miu[0]) ** 2) / (2 * (sigma[0] ** 2))))).sum()\n",
        "    pred1 = (np.prod((1 / (np.sqrt(2 * np.pi) * sigma[1])) * np.exp(-((x - miu[1]) ** 2) / (2 * (sigma[1] ** 2))))).sum()\n",
        "    #print(prior[0].shape)\n",
        "    #print(xtest.values.shape)\n",
        "    preds.append(0 if (pred0*prior[0]) > (pred1*prior[1]) else 1)\n",
        "  return preds\n",
        "\n",
        "y_pred_gnb = Gnbprd(X_test, mius, sigmas, priors)"
      ],
      "metadata": {
        "id": "zAH1FeOvQ9ls"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"accuracy: {accuracy_score(y_test, y_pred_gnb)}\")\n",
        "print(f\"f1Score: {f1_score(y_test, y_pred_gnb, average = 'macro')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkPyEj8jgalb",
        "outputId": "cb4b9ef0-9132-43fa-f045-1b4af878061a"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.5991071428571428\n",
            "f1Score: 0.5309265897501192\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ori_data = pd.read_csv('/content/gdrive/MyDrive/CS274/CS274H04/hw4_cluster.csv')\n",
        "colnames = list(ori_data.columns[1:-1])\n",
        "ori_data = ori_data.values"
      ],
      "metadata": {
        "id": "2PvZHUj2G5cG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initiate_centroids(K, dset, initialization):\n",
        "  if initialization == 'random':\n",
        "    np.random.shuffle(dset)\n",
        "    return dset[:K]\n",
        "  elif initialization == 'random_seed':\n",
        "    np.random.seed(4)  # Set a seed for reproducibility\n",
        "    random_indices = np.random.choice(len(dset), K, replace=False)\n",
        "    #print(dset.values[random_indices])\n",
        "    return dset[random_indices]"
      ],
      "metadata": {
        "id": "rnq0Kttfib_a"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_distance(point, centroid):\n",
        "  #print(point)\n",
        "  #print(centroid)\n",
        "  return np.square(np.sum((point- centroid)**2))"
      ],
      "metadata": {
        "id": "EMA2SuSWlGqS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def centroid_assignation(clusters, centroid_method):\n",
        "  centroids = []\n",
        "  if centroid_method == 'mean':\n",
        "    for cluster in clusters:\n",
        "      centroids.append(np.mean(cluster, axis=0))\n",
        "  return np.array(centroids)"
      ],
      "metadata": {
        "id": "NTaeFb9Uvi_l"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def k_means(data, K,  initialization, max_iter, centorid_method = 'mean'):\n",
        "  centroids = initiate_centroids( K,data, initialization)\n",
        "  #print(centroids)\n",
        "  for c in range(max_iter):\n",
        "    clusters = [[] for c in range(K)]\n",
        "    last_clusters = None\n",
        "    for point in data:\n",
        "      distances = [calculate_distance(point, centroid) for centroid in centroids]\n",
        "      closest_centroid = np.argmin(distances)\n",
        "      clusters[closest_centroid].append(np.array(point))\n",
        "    if last_clusters is not None and np.array_equal(clusters, last_clusters):\n",
        "      break\n",
        "    last_clusters = clusters.copy()\n",
        "    centroids = centroid_assignation(clusters, centorid_method)\n",
        "  return clusters\n"
      ],
      "metadata": {
        "id": "NaNuMTWn7Aj5"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_samples #for test purpose, for implement from scrach one see below\n",
        "\n",
        "def calculate_silhouette_score(clusters):\n",
        "    data = np.concatenate(clusters)\n",
        "    labels = np.concatenate([[i]*len(cluster) for i, cluster in enumerate(clusters)])\n",
        "    silhouette_vals = silhouette_samples(data, labels)\n",
        "    mean_silhouette = np.mean(silhouette_vals)\n",
        "    return mean_silhouette\n"
      ],
      "metadata": {
        "id": "0HsvYHWUEI-M"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clusters = k_means(ori_data, 5, 'random_seed', 50 )\n",
        "\n",
        "silhouettescore = calculate_silhouette_score(clusters)\n",
        "print(f\"silhouettescore:{silhouettescore}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxZaAEUTEUAj",
        "outputId": "8d44e036-213d-4b19-d305-97b6b0cd6a13"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "silhouettescore:0.5900989263516132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def silhouette(clusters):\n",
        "\n",
        "  scores = []\n",
        "  for i, pointS in enumerate(clusters):\n",
        "    for point in pointS:\n",
        "      #current_label = labels[i]\n",
        "      if len(pointS) > 1:\n",
        "        a = np.sum([(point-q)**2 for q in pointS])/ (len(pointS)-1)\n",
        "        #print(a)\n",
        "      else:\n",
        "        a = 0\n",
        "\n",
        "      b = np.inf\n",
        "      for j, other_cluster in enumerate(clusters):\n",
        "        if j != i:\n",
        "          mean_dist = np.mean([(point-q)**2 for q in other_cluster])\n",
        "          if mean_dist < b:\n",
        "            b = mean_dist\n",
        "\n",
        "\n",
        "    silhouette = (b - a) / max(a, b) if max(a, b) > 0 else 0\n",
        "    scores.append(silhouette)\n",
        "  return np.mean(scores)"
      ],
      "metadata": {
        "id": "HUjStD4RnUFL"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clusters = k_means(ori_data, 5, 'random_seed', 50 )\n",
        "silhouettescore = silhouette(clusters)\n",
        "print(f\"silhouettescore:{silhouettescore}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mnopM6JndRx",
        "outputId": "f8325bff-799a-4f24-ba49-1716a6360d00"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "silhouettescore:0.5167196842408075\n"
          ]
        }
      ]
    }
  ]
}